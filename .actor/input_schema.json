{
  "title": "RAG Spider Input Configuration",
  "description": "Configuration for the RAG Spider web crawler that extracts clean content for AI training",
  "type": "object",
  "schemaVersion": 1,
  "properties": {
    "startUrls": {
      "title": "Start URLs",
      "type": "array",
      "description": "List of URLs where the crawler will start. Supports Apify requestListSources format.",
      "editor": "requestListSources",
      "items": {
        "type": "object",
        "properties": {
          "url": {
            "title": "URL",
            "type": "string",
            "pattern": "^https?://.+",
            "description": "The URL to crawl"
          }
        },
        "required": ["url"]
      },
      "minItems": 1
    },
    "crawlDepth": {
      "title": "Crawl Depth",
      "type": "integer",
      "description": "Maximum depth to crawl from starting URLs. Set to 1 to crawl only start URLs, 2 to include one level of links, etc.",
      "default": 2,
      "minimum": 1,
      "maximum": 10
    },
    "includeUrlGlobs": {
      "title": "Include URL Patterns (Optional)",
      "type": "array",
      "description": "Optional glob patterns to limit crawling scope. Leave empty to crawl all discovered links. Only URLs matching these patterns will be processed. Example: ['https://docs.example.com/**']",
      "items": {
        "type": "string"
      },
      "default": []
    },
    "chunkSize": {
      "title": "Chunk Size",
      "type": "integer",
      "description": "Maximum number of characters per chunk for RAG processing. Larger chunks provide more context but may exceed model limits.",
      "default": 1000,
      "minimum": 100,
      "maximum": 8000
    },
    "chunkOverlap": {
      "title": "Chunk Overlap",
      "type": "integer",
      "description": "Number of characters to overlap between consecutive chunks to preserve context across boundaries.",
      "default": 100,
      "minimum": 0,
      "maximum": 500
    },
    "proxyConfiguration": {
      "title": "Proxy Configuration",
      "type": "object",
      "description": "Proxy settings for the crawler to avoid rate limiting and IP blocks",
      "editor": "proxy",
      "default": {
        "useApifyProxy": true
      },
      "prefill": {
        "useApifyProxy": true
      }
    },
    "maxRequestsPerCrawl": {
      "title": "Max Requests Per Crawl",
      "type": "integer",
      "description": "Maximum number of pages to process in a single crawl run",
      "default": 1000,
      "minimum": 1,
      "maximum": 10000
    },
    "requestDelay": {
      "title": "Request Delay (ms)",
      "type": "integer",
      "description": "Delay between requests in milliseconds to be respectful to target servers",
      "default": 1000,
      "minimum": 0,
      "maximum": 10000
    }
  },
  "required": [
    "startUrls"
  ]
}